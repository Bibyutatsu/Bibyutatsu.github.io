// Auto-generated from ResumeAssets.xlsx
// Last updated: 2026-01-25T09:33:48.005Z
const portfolioData = {
  "PatentsPublications": [
    {
      "Type": "Patent",
      "Name": "Quantum computing approaches for resource allocation",
      "URL": "https://patents.google.com/patent/US20250252335A1"
    },
    {
      "Type": "Patent",
      "Name": "Quantum-computing-enhanced systems and methods for entity allocation",
      "URL": "https://patents.google.com/patent/US20250165824A1"
    },
    {
      "Type": "Patent",
      "Name": "Traffic flow optimization for a multi-class vehicle network using quantum computing",
      "URL": "https://patents.google.com/patent/US20250104559A1"
    },
    {
      "Type": "Patent",
      "Name": "System and method for generating a novel molecular structure using a protein structure",
      "URL": "https://patents.google.com/patent/US20220406403A1/en?oq=20220406403"
    },
    {
      "Type": "Patent",
      "Name": "System and method for generating customizable molecular structures for drug discovery",
      "URL": "https://patents.google.com/patent/US20230115171A1/en?oq=US20230115171A1"
    },
    {
      "Type": "Paper",
      "Name": "Optimal Path Generation for Simultaneous Rendezvous of Fixed-Wing UAVs in 3D Dynamic Environments",
      "URL": "https://arc.aiaa.org/doi/10.2514/6.2019-1166"
    }
  ],
  "Certifications": [
    {
      "Provider": "AWS",
      "Name": "AWS Certified Machine Learning - Specialty",
      "URL": "https://cp.certmetrics.com/amazon/en/public/verify/credential/e7b1ab967c3247bc8b8477a0f0da0019"
    },
    {
      "Provider": "AWS",
      "Name": "AWS Certified AI Practitioner",
      "URL": "https://cp.certmetrics.com/amazon/en/public/verify/credential/2c6a95f7989046d0a5bcc4352e351e5d"
    },
    {
      "Provider": "AWS",
      "Name": "AWS Certified Cloud Practitioner",
      "URL": "https://cp.certmetrics.com/amazon/en/public/verify/credential/2d038a52d6a8441190b429a55d87c7d4"
    },
    {
      "Provider": "Microsoft",
      "Name": "Microsoft Certified: Azure AI Engineer - Associate",
      "URL": "https://learn.microsoft.com/api/credentials/share/en-us/BibhashMitra/90AEC65E5A4A8FFD?sharingId=39DEA8414B60265"
    },
    {
      "Provider": "Google",
      "Name": "Google Data Analytics Professional Certificate",
      "URL": "https://www.credly.com/badges/c5987d48-dac8-462d-a6ea-28cf6b72b5fa/public_url"
    },
    {
      "Provider": "IBM",
      "Name": "Data Science Professional Certificate",
      "URL": "https://www.credly.com/badges/e6ed7df5-7daf-4240-943c-8ba585985be0/public_url"
    },
    {
      "Provider": "Coursera",
      "Name": "Deep Learning Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/certificate/7YA55DLQFVQ4"
    },
    {
      "Provider": "Coursera",
      "Name": "Generative Adversarial Networks (GANs) Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/8XBN32GQLH7B"
    },
    {
      "Provider": "Coursera",
      "Name": "Google Data Analytics Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/certificate/62QBRLAXMQPY"
    },
    {
      "Provider": "Coursera",
      "Name": "IBM Data Science Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/certificate/B69K4TTFL7D5"
    },
    {
      "Provider": "Coursera",
      "Name": "Python 3 Programming Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/certificate/UF4HUSYMR7GW"
    },
    {
      "Provider": "Coursera",
      "Name": "Generative AI Specialization",
      "URL": "https://www.coursera.org/account/accomplishments/specialization/certificate/GZ4QPHKSPPEJ"
    }
  ],
  "Credly": [
    {
      "Badge": "AWS Certified Machine Learning – Specialty",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"0bc048fc-c019-411f-ab6f-1544664ec033\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "AWS Certified Cloud Practitioner",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"407c748f-568d-4aab-97bc-7153f79550f6\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "AWS Certified AI Practitioner Early Adopter",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"6e3b9311-fc18-47a9-b204-f8ebfac7e154\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "AWS Certified AI Practitioner",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"dbe3e6eb-01f9-4f3b-b431-fa887016698e\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Inclusive Mindset",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"ae2fc8da-312d-486d-ba9c-55981d08dea2\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Digital Acumen",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"7fad8267-8713-4aff-805c-6f7490198d89\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Human-Centered Design",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"96703463-59fb-4e6d-b281-e0ccdad46461\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Google Data Analytics Professional Certificate",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"c5987d48-dac8-462d-a6ea-28cf6b72b5fa\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Data Science Professional Certificate",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"e6ed7df5-7daf-4240-943c-8ba585985be0\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Machine Learning with Python",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"5569b3c5-0893-480b-8e36-2c751b5276fa\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Data Visualization with Python",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"67a6bfaa-57e6-4e11-ab19-b6947f33baca\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Data Analysis with Python",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"cb0eb950-676a-476e-81be-167ae1655eaf\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Databases and SQL for Data Science",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"f09e587c-71ed-4e2b-8785-d7b03013e45f\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Python for Data Science and AI",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"58a7097b-f0f4-41dd-9f71-c4c5b1ddb99f\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Data Science Methodology",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"d6b09c86-3730-433c-93be-fc06ea4852e3\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Tools for Data Science",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"47562298-1cd3-492e-8c5d-6517f1873638\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "Data Science Orientation",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"4ce08ed3-114f-4150-b280-b366721cf3e4\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "ADAA 2017 Participant",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"6815f7ab-eeda-46ca-8f26-fd219b4076c8\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    },
    {
      "Badge": "IBM Blockchain Essentials",
      "Embed code": "<div data-iframe-width=\"150\" data-iframe-height=\"270\" data-share-badge-id=\"1b755f40-0aed-45a4-b8df-2f087d82f57c\" data-share-badge-host=\"https://www.credly.com\"></div><script type=\"text/javascript\" async src=\"//cdn.credly.com/assets/utilities/embed.js\"></script>"
    }
  ],
  "Internships": [
    {
      "company": "Innoplexus Consulting Services, Pvt. Ltd.",
      "role": "Data Science Intern",
      "dateRange": "May 2018 - July 2018",
      "projectTitle": "Document Image Segmentation & Table Extraction",
      "projectDescription": "Built tools to extract structured data from scientific paper images. Used classical image-processing and machine-learning techniques to segment a page into Title, Authors, Affiliations, Abstract, etc., then applied Tesseract OCR (and improved Asprise/Tabula wrappers) to convert each region into text. Simultaneously, a deep-learning table-detection model identified tables and converted them into CSV format. These pipelines enabled automated conversion of document images to structured data, and contributions were made upstream to the open-source Tesseract project."
    },
    {
      "company": "Invention Labs",
      "role": "Data Science Intern",
      "dateRange": "May 2017 - July 2017",
      "projectTitle": "Language Processing Engine",
      "projectDescription": "Developed a prototype NLP engine capable of parsing and structuring text for a new language. Applied machine learning with decision-tree algorithms to convert raw sentences into parse-tree structures and then map these to a universal representation. This work contributed to building a language-specific processing pipeline, enabling automated understanding of sentence structure."
    }
  ],
  "Experience": [
    {
      "company": "PwC",
      "logoPath": "images/Logo/pricewaterhousecoopers-pwc-logo-png_seeklogo-619359.png",
      "role": "Manager (AI/ML)",
      "dateRange": "June 2024 – Present",
      "projects": [
        {
          "title": "Azure Agentic Data Ingestion & Schema Standardization Platform (Financial Services)\n",
          "description": "Architected and deployed an Azure-hosted multi-agent ingestion and transformation platform for a financial client that automatically standardizes semi-structured inputs into a structured, analytics-ready schema, cutting database ingestion from 10 hours to 15 minutes (approx. 40x) and accelerating downstream reporting and visualization."
        },
        {
          "title": "Agentic AI Lead Scoring & Financial Filings Intelligence (Healthcare)",
          "description": "Developed and launched an agentic AI lead-scoring engine for a healthcare enterprise that extracts and evaluates signals from 10-K and 10-Q reports across 17 weighted criteria, cutting lead qualification from 3-5 days to 4-5 hours and substantially improving pipeline focus on the most promising leads."
        },
        {
          "title": "Azure Multi-Agent Insights Engine (Text-to-SQL + Automated Analytics + BI Visualization)",
          "description": "Designed an Azure-hosted agentic analytics and insights platform that converts natural-language questions into SQL, runs automated exploratory/diagnostic analysis on structured + unstructured data, and produces narrative insights with dashboards, cutting the median time-to-insight for common business questions by 67-90%."
        },
        {
          "title": "GraphRAG + Collaborative Filtering Personalization Engine (Behavioral KG, LLM Reasoning)\n",
          "description": "Designed a hybrid personalization engine that merges knowledge-graph behavioral signals with LLM-powered \nGraphRAG reasoning and collaborative filtering to generate highly contextual product/campaign recommendations—resulting in a 20% uplift in CTOR for targeted customer communications."
        }
      ]
    },
    {
      "company": "PwC",
      "logoPath": "images/Logo/pricewaterhousecoopers-pwc-logo-png_seeklogo-619359.png",
      "role": "Senior Associate (AI/ML)",
      "dateRange": "June 2022 – June 2024",
      "projects": [
        {
          "title": "RAG-Based Customer Support Email Automation with Verified Citations (Hospitality)\n",
          "description": "Implemented a production customer-support automation pipeline for a hospitality enterprise that uses RAG-powered retrieval to draft policy-accurate, citation-backed email responses at scale, driving a 43% uplift in satisfaction, a 34% increase in first-contact resolution, and a 3.5x reduction in time-to-resolution."
        },
        {
          "title": "Enterprise PDF QA & Retrieval System (Semantic Kernel + Azure Cognitive Search + OpenAI)",
          "description": "Led end-to-end implementation of enterprise PDF question-answering platforms at scale, combining Semantic Kernel orchestration, Azure Cognitive Search indexing, and OpenAI LLMs to deliver grounded, high-precision retrieval and answers, boosting retrieval quality and reducing support/analysis effort via self-serve knowledge access."
        },
        {
          "title": "CEFR Spoken-English Scoring & Time-Stamped Feedback Engine (ASR + LLM Fine-Tuning)",
          "description": "Engineered a CEFR speech scoring and feedback engine, combining Whisper-based transcription with lexical/syntactic/prosodic feature engineering and a fine-tuned GPT-3.5 classifier, reaching a Quadratic Weighted Kappa (QWK) of 0.54 and generating time-specific coaching feedback to help learners improve targeted speaking skills."
        },
        {
          "title": "Multimodal Vision–Language Demo & Analytics Reporting (CLIP + GIT)",
          "description": "Delivered an interactive multimodal interactive demo application for CLIP + GIT, enabling stakeholders to test and visualize model behavior across vision–language \nuse cases (image-to-text). Complemented the demo with automated analytics and reporting pipelines that blended statistical analysis with model outputs to produce executive-ready dashboards and insights."
        },
        {
          "title": "Content-Based Image Search with Captioning",
          "description": "Built an image retrieval system that interprets visual queries. Using CLIP embeddings, the engine finds the top-3 images from a large gallery matching a text or image query, then generates descriptive captions for the input image. This tool supports intuitive image browsing and annotation, useful for media and marketing teams to quickly find and describe relevant imagery."
        }
      ]
    },
    {
      "company": "PwC",
      "logoPath": "images/Logo/pricewaterhousecoopers-pwc-logo-png_seeklogo-619359.png",
      "role": "Experienced Associate (AI/ML)",
      "dateRange": "Nov 2021 – June 2022",
      "projects": [
        {
          "title": "Active-Learning NLP Pipeline for Low-Data Training (Label Studio + Hybrid Modeling)",
          "description": "Deployed a hybrid NLP system designed for low-data environments, integrating active learning in Label Studio to prioritize high-value samples and training lightweight deep learning + rule-based models—driving a 45% performance uplift while cutting labeling workload and minimizing dependence on large training datasets."
        },
        {
          "title": "Quantum Annealing Optimization for Last-Mile Routing & Workforce Scheduling (Food Chain)",
          "description": "Formulated a quantum-annealing–based optimization approach for a large food-service chain’s vehicle routing and staffing decisions, translating operational constraints into an annealable objective and driving 35% lower routing costs plus 20% higher on-time delivery performance in simulated and pilot runs."
        },
        {
          "title": "Personalized Product Recommender",
          "description": "Built a hybrid recommendation engine for large-scale retail data. Combined collaborative filtering with content-based features to suggest products tailored to each user’s behavior and preferences. The system processes massive interaction logs to improve user engagement and support cross-selling, enhancing the personalization of customer experiences."
        }
      ]
    },
    {
      "company": "Innoplexus",
      "logoPath": "images/Logo/Innoplexus-logo.png",
      "role": "Associate Data Scientist",
      "dateRange": "June 2019 – Nov 2021",
      "projects": [
        {
          "title": "Novel Molecule Generation for Drug DProtein-Conditioned Generative Molecular Design for Drug Discovery (PDB + ZINC/MOSES)iscovery",
          "description": "Created an end-to-end protein-conditioned molecular generation platform for computational drug discovery, fusing PDB-derived protein structure signals with large compound corpora to propose target-specific candidate molecules. Designed a multi-stage generative pipeline (JT-VAE/VAE → GAN) and applied RL with SOM-shaped rewards to steer sampling toward drug-like chemical space; created custom SMILES tokenization and ran large-scale ZINC/MOSES benchmarks, helping secure $1M in funding and industry/media visibility (e.g., NVIDIA Inception, GTC 2020, WSJ/Forbes)."
        },
        {
          "title": "Explainable Disease–Gene Prioritization Pipeline (Omics ML + SHAP)",
          "description": "Built an Explainable AI based workflow for disease–gene prioritization, training predictive models on genomic/omics datasets and using SHAP-based feature attribution to produce transparent gene rankings. Reached ~85% mAP@5, enabling interpretable discovery of likely causal genes and establishing a scalable foundation for multi-omics integration in target identification."
        },
        {
          "title": "Automated Structure-Based Drug Design Pipeline (Docking + ADMET + Lead Prioritization)",
          "description": "Automated a computational drug discovery workflow that filters compounds, runs AutoDock Vina docking against structure-based protein targets, and scores/ranks molecules using ADMET and Lipinski constraints to surface high-quality leads. The pipeline streamlined protein- and metabolism-aware screening by replacing manual docking and triage with repeatable, scalable automation."
        },
        {
          "title": "Event-Driven Demand Forecasting + Knowledge Graph Enrichment (LSTM, News Embeddings, Pharma KG)",
          "description": "Operationalized a hybrid time-series + news-driven demand forecasting model using an LSTM with sparse event/news embeddings, achieving 12.5% MAPE with strong confidence gating and low error in backtests. Operationalized outputs to update a pharma knowledge graph (drugs, trials, entities), boosting query weighting and downstream answer/retrieval relevance for drug-focused user requests."
        },
        {
          "title": "Document Data Extraction (PDFs & Tables)",
          "description": "Created automated pipelines to parse and extract data from documents. For PDFs, the system segments paragraphs (using rule-based image processing) and applies Tesseract OCR to convert scanned or digital PDFs into structured content. For tables, a combination of rule-based methods and a Faster R-CNN model detects and isolates tables; a custom \"Table-Maker\" then normalizes any table format into standard CSV and uses Tesseract to extract text. These tools together enabled reliable conversion of complex documents into machine-readable datasets."
        },
        {
          "title": "Ontology-Guided Hierarchical Disease Classification (BERT + GCN, Multi-Label NLP)",
          "description": "Developed a hierarchical, multi-label disease classification pipeline for clinical/biomedical text by fine-tuning BERT for coarse disease categories and using an ontology-informed GCN to propagate relationships and refine final labels. The resulting taxonomy-driven approach improved classification quality for overlapping disease concepts and enabled more reliable downstream clinical and translational \nanalytics.\n"
        },
        {
          "title": "ML Deployment Infrastructure (TorchServe & MLflow)",
          "description": "Established a scalable model-serving and version-control framework. Packaged deep-learning models with TorchServe and tracked experiments in MLflow, automating deployment to production. This infrastructure enabled continuous integration and versioning of ML models, significantly reducing manual overhead in operations."
        }
      ]
    }
  ]
};
